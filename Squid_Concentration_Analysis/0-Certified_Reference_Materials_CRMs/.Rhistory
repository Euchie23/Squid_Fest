# print(year)
# print(month)
}
}
# Step 1: Fit the regression model using the training data
if (nrow(training_data_m) > 0) {
full_model <- lm(Ln_CPUE_plus_c ~ AvgWaterTemp + AvgDepth + AvgEasting + AvgNorthing +
Month1 + Month2 + Month3 + Month4 + Month5 + Month6 +
Month7 + Month8 + Month11 + Month12, data = training_data_m)
# Step 2: Stepwise regression to select the best model based on AIC
stepwise_model <- step(full_model, direction = "both", trace = FALSE)
print(year)
print(stepwise_model)
# Step 3: Save regression results
regression_results <- list(
Year = year,
Month = month,
Coefficients = coef(stepwise_model),
R_squared = summary(stepwise_model)$r.squared,
Adjusted_R_squared = summary(stepwise_model)$adj.r.squared
)
# Conditional VIF calculation
if (length(coef(stepwise_model)) > 2) { # Ensure more than 1 predictor
regression_results$VIF <- vif(stepwise_model)
} else {
regression_results$VIF <- "Not applicable: fewer than 2 predictors"
}
regression_results_list[[as.character(year)]] <- regression_results
# Step 4: Predict Ln_CPUE_plus_c for the prediction data
if (nrow(prediction_data_m) > 0) {
prediction_data_m$Predicted_Ln_CPUE_plus_c <- predict(stepwise_model, newdata = prediction_data_m)
#print(as.data.frame(prediction_data_m))
prediction_data_m <- prediction_data_m %>%
mutate(Standardized_CPUE = exp(Predicted_Ln_CPUE_plus_c) - cumulative_mean_CPUE_10perc)
prediction_data_all[[as.character(year)]] <- prediction_data_m
}
}
}
# Combine all prediction data for the last 3 months into a single dataframe
prediction_data_combined <- do.call(rbind, prediction_data_all)
rownames(prediction_data_combined) <- NULL
#print(prediction_data_combined)
# Subset only the required columns for the last 3 months
prediction_data_subset <- prediction_data_combined %>%
mutate(
Predicted_CPUE = exp(Predicted_Ln_CPUE_plus_c),  # Convert log-predicted values to normal scale
Standardized_CPUE = Predicted_CPUE - cumulative_mean_CPUE_10perc  # Subtract cumulative mean CPUE (10%)
) %>%
select(
Year,
Month,
Season,
CPUE = daily_CPUE_kg,
Standardized_CPUE
)
training_data_subset <- training_data_mm %>%
mutate(  # Convert log-predicted values to normal scale
Standardized_CPUE = NA  # Subtract cumulative mean CPUE (10%)
) %>%
select(
Year,
Month,
Season,
CPUE = daily_CPUE_kg,
Standardized_CPUE
)
#prediction_data_subset <- prediction_data_subset[-183,]
full_df <- rbind(training_data_subset, prediction_data_subset)
rownames(full_df) <- NULL
# Summarize CPUE and Standardized_CPUE by Year and Month
# Summarize CPUE and Standardized_CPUE by Year and Month
sum_full_df <- full_df %>%
group_by(Year, Month) %>%
summarize(
Total_CPUE = if (all(is.na(CPUE))) NA_real_ else sum(CPUE, na.rm = TRUE),
Total_Standardized_CPUE = if (all(is.na(Standardized_CPUE))) NA_real_ else sum(Standardized_CPUE, na.rm = TRUE),
.groups = "drop"
)
# Prevent scientific notation globally
options(scipen = 999)
# Save the regression results in a readable format
regression_results_df <- do.call(rbind, lapply(regression_results_list, function(x) {
data.frame(
Year = x$Year,
R_squared = x$R_squared,
Adjusted_R_squared = x$Adjusted_R_squared,
Coefficients = paste(names(x$Coefficients), x$Coefficients, sep = "=", collapse = "; "),
VIF = paste(names(x$VIF), x$VIF, sep = "=", collapse = "; ")
)
}))
# Save results to an Excel file
wb <- createWorkbook()
# Add the full dataset with predictions for the last 3 months
addWorksheet(wb, "Last_Three_Months")
writeData(wb, "Last_Three_Months", prediction_data_subset)
# Add regression results for each year
addWorksheet(wb, "Regression_Results")
writeData(wb, "Regression_Results", regression_results_df)
# Add regression results for each year
addWorksheet(wb, "full_Results")
writeData(wb, "full_Results", full_df)
# Save the Excel workbook
saveWorkbook(wb, "Regression_and_Standardized_CPUE.xlsx", overwrite = TRUE)
# Print a success message
cat("Results saved to 'Regression_and_Standardized_CPUE.xlsx'")
#MAKING THE GRAPH FOR TRAINING DATA AND PREDICTED DATA (FOR THE MONTH)
# Assuming `data` is your dataframe
data_long <- sum_full_df %>%
pivot_longer(
cols = c(Total_CPUE, Total_Standardized_CPUE), # Convert these columns to long format
names_to = "Metric",               # New column for metric type
values_to = "Value"                # New column for metric values
) %>%
mutate(
Metric = case_when(
Metric == "Total_CPUE" ~ "Nominal CPUE",
Metric == "Total_Standardized_CPUE" ~ "Standardized CPUE",
TRUE ~ Metric
)
) %>%
mutate(
Value = Value / 1000  # Convert values to metric tons
)
data_long_new <- data_long[-96,]
# Create the plot with explicit grouping
ggplot(data_long_new, aes(x = factor(Month), y = Value, color = Metric, group = interaction(Year, Metric))) +
geom_line(size = 1) +# Draw horizontal lines connecting points
geom_point(size = 2) +
facet_wrap(~ Year, scales = "free_y") +         # One graph per year
scale_color_manual(values = c("Nominal CPUE" = "blue",
"Standardized CPUE" = "red")) +
labs(
title = "Nominal CPUE Vs Standardized CPUE for Each Year (GLBM) ",
x = "Month",
y = "Catch Per Unit Effort (Metric Tons)",
color = "Metric Type"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels for clarity
axis.text.y = element_text(size = 10),
legend.position = "top"
) +
scale_y_continuous(labels = scales::comma)  # Avoid scientific notation on y-axis
complex_gam_ia_catch <- subset(gam_ia_catch_final, (Month == 3 & Day >= 1) |
(Month == 4) |
(Month == 5 & Day <= 31))
# Load and modify data
gam_ia_catch<-sum_ia_catch_v1
gam_ia_catch_final<- gam_ia_catch[,-c(24:25)]
gam_ia_catch_final$Log_CPUE_plus_1 <- log10(sum_ia_catch_v1$daily_CPUE_kg+1)
complex_gam_ia_catch <- gam_ia_catch_final
complex_gam_ia_catch$Month <- as.numeric(complex_gam_ia_catch$Month)
# GAM YEAR (One graph)----
complex_gam_ia_catch <- subset(gam_ia_catch_final, (Month == 3 & Day >= 1) |
(Month == 4) |
(Month == 5 & Day <= 31))
complex_gam_ia_catch$Month <- as.numeric(complex_gam_ia_catch$Month)
str(complex_gam_ia_catch)
# 2. Calculate Total CPUE per year by summing the CPUE values for each year
total_cpue_per_year <- aggregate(daily_CPUE_kg ~ Year, data = complex_gam_ia_catch, FUN = sum)
# Split data into training (2000-2015) and prediction (2016-2020) sets
training_data11 <- subset(complex_gam_ia_catch, Year <= 2015)
prediction_data11 <- subset(complex_gam_ia_catch, Year > 2015)
# Create an empty column for standardized CPUE
complex_gam_ia_catch$Standardized_CPUE <- NA
# Train the GAM model on 2000-2015 data
gam_model <- gam(
log(daily_CPUE_kg + 1) ~ s(Month, k = 3) + s(AvgNorthing, k = 5) +
s(AvgEasting, k = 5) + s(AvgWaterTemp, k = 5) + s(AvgDepth, k = 5),
data = training_data11,
family = gaussian(link = "identity")
)
# Use the model to predict standardized CPUE for 2016-2020
prediction_data11$Standardized_CPUE <- exp(predict(gam_model, newdata = prediction_data11)) - 1
training_data11$Standardized_CPUE <- NA
# Combine the predicted data back into the main dataset
complex_gam_ia_catch <- rbind(
training_data11,
prediction_data11
)
# Assuming gam_model is your fitted GAM model
summary(gam_model)  # This gives you the smooth terms and their significance
# Extract coefficients for smooth terms and the intercept
coefficients(gam_model)
# You can also extract the smooth terms' coefficients
gam_model$coefficients  # This will show the coefficients for each smooth term
# Get the overall model summary
summary(gam_model)
# If you want to extract the estimated degrees of freedom for the smooth terms:
gam_model$edf  # Estimated degrees of freedom for each smooth term
# To get the GAM model's intercept and coefficients (for a linear predictor part of the model)
gam_model$coefficients[1]  # This is often the intercept (depending on the model formulation)
# Save the updated dataset to an Excel file
write.xlsx(complex_gam_ia_catch, "dataset_after_training_and_prediction.xlsx")
# Summarize the data by Year and Month
complex_gam_ia_catch_summary <- complex_gam_ia_catch %>%
group_by(Year, Month) %>%
summarise(
Monthly_Nominal_CPUE = sum(daily_CPUE_kg, na.rm = TRUE) / 1000,       # Convert to metric tons
Monthly_Standardized_CPUE = sum(Standardized_CPUE, na.rm = TRUE) / 1000  # Convert to metric tons
) %>%
gather(key = "CPUE_Type", value = "CPUE_Value", Monthly_Nominal_CPUE, Monthly_Standardized_CPUE)
# Create multi-faceted graph
ggplot(complex_gam_ia_catch_summary, aes(x = factor(Month), y = CPUE_Value, color = CPUE_Type, group = CPUE_Type)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
facet_wrap(~ Year, scales = "free_y", ncol = 3) +
scale_color_manual(values = c("Monthly_Nominal_CPUE" = "blue", "Monthly_Standardized_CPUE" = "red"),
labels = c("Nominal CPUE", "Standardized CPUE")) +
theme_minimal() +
labs(
title = "Monthly Comparison of Summed CPUE Types by Year (2000-2020)",
x = "Month",
y = "CPUE (metric tons)"
) +
scale_y_continuous(labels = scales::comma) +
theme(
legend.title = element_blank(),
strip.text = element_text(size = 8),
legend.position = "bottom"
)
# Summarize the data by Year
annual_summary <- complex_gam_ia_catch %>%
group_by(Year) %>%
summarise(
Total_Nominal_CPUE = sum(daily_CPUE_kg, na.rm = TRUE) / 1000,         # Convert to metric tons
Total_Standardized_CPUE = sum(Standardized_CPUE, na.rm = TRUE) / 1000  # Convert to metric tons
) %>%
gather(key = "CPUE_Type", value = "CPUE_Value", Total_Nominal_CPUE, Total_Standardized_CPUE)
# Create the single graph
# Replace 0 with NA in a specific column (e.g., Column1)
annual_summary$CPUE_Value[annual_summary$CPUE_Value == 0] <- NA
ggplot(annual_summary, aes(x = Year, y = CPUE_Value, color = CPUE_Type, group = CPUE_Type)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
scale_color_manual(values = c("Total_Nominal_CPUE" = "blue", "Total_Standardized_CPUE" = "red"),
labels = c("Nominal CPUE", "Standardized CPUE")) +
theme_minimal() +
labs(
title = "Annual Comparison of Total CPUE Types (2000-2020) for General Additive Model",
x = "Year",
y = "Total CPUE (metric tons)"
) +
scale_y_continuous(labels = scales::comma) +
theme(
legend.title = element_blank(),
legend.position = "bottom"
)
# Save results to an Excel file
wb <- createWorkbook()
# Add the full dataset with predictions for the last 3 months
addWorksheet(wb, "Last_Five_Years")
writeData(wb, "Last_Five_Years", annual_summary[38:42,])
# Add regression results for each year
addWorksheet(wb, "Regression_Results")
writeData(wb, "Regression_Results", regression_results_df)
# Add regression results for each year
addWorksheet(wb, "full_Results")
writeData(wb, "full_Results", annual_summary)
# Save the Excel workbook
saveWorkbook(wb, "Regression_and_Standardized_CPUE_GAM_complex_model.xlsx", overwrite = TRUE)
# Print a success message
cat("Results saved to 'Regression_and_Standardized_CPUE_GAM_complex_model.xlsx'")
# Step 1: Initialize and preprocess the data
complex_gam_ia_catch <- gam_ia_catch_final
complex_gam_ia_catch$Month <- as.numeric(complex_gam_ia_catch$Month)
complex_gam_ia_catch$Year <- as.character(complex_gam_ia_catch$Year)
# Initialize empty data frames for accumulated data and results
data_accum <- data.frame(matrix(NA, nrow = 0, ncol = ncol(complex_gam_ia_catch)))
results_list <- list()
# Step 2: Data accumulation and seasonal segmentation
for (year in unique(complex_gam_ia_catch$Year)) {
# Subset data for the current year
year_data <- complex_gam_ia_catch %>% filter(Year == year)
# Calculate number of months for segmentation
num_months <- length(unique(year_data$Month))
threshold_month <- ifelse(num_months > 2, round(0.75 * num_months), num_months)
# Assign seasons: Training (earlier months) and Prediction (later months)
year_data <- year_data %>%
mutate(Season = ifelse(Month <= threshold_month, "Training", "Prediction"))
# Combine the segmented data into the accumulated dataset
data_accum <- rbind(data_accum, year_data)
}
# Step 3: Loop through each year for GAM modeling
for (year in unique(data_accum$Year)) {
# Separate training and prediction datasets for the year
year_data <- data_accum %>% filter(Year == year)
training_data <- year_data %>% filter(Season == "Training")
prediction_data <- year_data %>% filter(Season == "Prediction")
# Skip years with insufficient training data
if (nrow(training_data) < 5) next
# Step 3.1: Fit GAM model on the training dataset
gam_model <- if (year == "2016") {
gam(
log(daily_CPUE_kg + 1) ~ s(Month, k = 2) + s(AvgNorthing, k = 2) +
s(AvgEasting, k = 2) + s(AvgWaterTemp, k = 2) + s(AvgDepth, k = 2),
data = training_data,
family = gaussian(link = "identity")
)
} else {
gam(
log(daily_CPUE_kg + 1) ~ s(Month, k = 4) + s(AvgNorthing, k = 5) +
s(AvgEasting, k = 5) + s(AvgWaterTemp, k = 5) + s(AvgDepth, k = 5),
data = training_data,
family = gaussian(link = "identity")
)
}
# Step 3.2: Make predictions for training and prediction datasets
training_data$Standardized_CPUE <- NA
# exp(predict(gam_model, newdata = training_data)) - 1
prediction_data$Standardized_CPUE <- exp(predict(gam_model, newdata = prediction_data)) - 1
# Combine results into a single dataset
year_results <- rbind(training_data, prediction_data)
results_list[[year]] <- list(model = gam_model, results = year_results)
}
# Step 4: Consolidate results
final_results <- do.call(rbind, lapply(results_list, function(x) x$results))
# Step 5: Save the results to a file
write.xlsx(final_results, "complex_gam_results.xlsx", overwrite = TRUE)
# Step 6: Create summary graphs (Nominal vs Standardized CPUE)
summary_data <- final_results %>%
group_by(Year, Month) %>%
summarize(
Monthly_Nominal_CPUE = sum(daily_CPUE_kg, na.rm = TRUE),
Monthly_Standardized_CPUE = sum(Standardized_CPUE, na.rm = TRUE)
) %>%
pivot_longer(
cols = c(Monthly_Nominal_CPUE, Monthly_Standardized_CPUE),
names_to = "CPUE_Type",
values_to = "CPUE_Value"
) %>%
mutate(CPUE_Value = CPUE_Value / 1000)  # Convert to metric tons
summary_data_new <- summary_data[-96,]
# Replace 0 with NA in a specific column using indexing
summary_data_new$CPUE_Value[summary_data_new$CPUE_Value == 0] <- NA
ggplot(summary_data_new, aes(x = factor(Month), y = CPUE_Value, color = CPUE_Type, group = CPUE_Type)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
facet_wrap(~ Year, scales = "free_y", ncol = 3) +
scale_color_manual(values = c("Monthly_Nominal_CPUE" = "blue", "Monthly_Standardized_CPUE" = "red")) +
theme_minimal() +
labs(
title = "Monthly CPUE Comparison by Year",
x = "Month",
y = "CPUE (metric tons)"
) +
theme(legend.position = "bottom")
gam_ia_catch<-sum_ia_catch_v1
gam_ia_catch_final<- gam_ia_catch[,-c(24:25)]
gam_ia_catch_final$Log_CPUE_plus_1 <- log10(sum_ia_catch_v1$daily_CPUE_kg+1)
complex_gam_ia_catch <- gam_ia_catch_final
complex_gam_ia_catch$Month <- as.numeric(complex_gam_ia_catch$Month)
# GAM YEAR (One graph)----
complex_gam_ia_catch <- subset(gam_ia_catch_final, (Month == 3 & Day >= 1) |
(Month == 4) |
(Month == 5 & Day <= 31))
complex_gam_ia_catch$Month <- as.numeric(complex_gam_ia_catch$Month)
str(complex_gam_ia_catch)
# 2. Calculate Total CPUE per year by summing the CPUE values for each year
total_cpue_per_year <- aggregate(daily_CPUE_kg ~ Year, data = complex_gam_ia_catch, FUN = sum)
# Split data into training (2000-2015) and prediction (2016-2020) sets
training_data11 <- subset(complex_gam_ia_catch, Year <= 2015)
prediction_data11 <- subset(complex_gam_ia_catch, Year > 2015)
# Create an empty column for standardized CPUE
complex_gam_ia_catch$Standardized_CPUE <- NA
# Train the GAM model on 2000-2015 data
gam_model <- gam(
log(daily_CPUE_kg + 1) ~ s(Month, k = 3) + s(AvgNorthing, k = 5) +
s(AvgEasting, k = 5) + s(AvgWaterTemp, k = 5) + s(AvgDepth, k = 5),
data = training_data11,
family = gaussian(link = "identity")
)
# Use the model to predict standardized CPUE for 2016-2020
prediction_data11$Standardized_CPUE <- exp(predict(gam_model, newdata = prediction_data11)) - 1
training_data11$Standardized_CPUE <- NA
# Combine the predicted data back into the main dataset
complex_gam_ia_catch <- rbind(
training_data11,
prediction_data11
)
# Assuming gam_model is your fitted GAM model
summary(gam_model)  # This gives you the smooth terms and their significance
# Extract coefficients for smooth terms and the intercept
coefficients(gam_model)
# You can also extract the smooth terms' coefficients
gam_model$coefficients  # This will show the coefficients for each smooth term
# Get the overall model summary
summary(gam_model)
# If you want to extract the estimated degrees of freedom for the smooth terms:
gam_model$edf  # Estimated degrees of freedom for each smooth term
# To get the GAM model's intercept and coefficients (for a linear predictor part of the model)
gam_model$coefficients[1]  # This is often the intercept (depending on the model formulation)
# Save the updated dataset to an Excel file
write.xlsx(complex_gam_ia_catch, "dataset_after_training_and_prediction.xlsx")
# Summarize the data by Year and Month
complex_gam_ia_catch_summary <- complex_gam_ia_catch %>%
group_by(Year, Month) %>%
summarise(
Monthly_Nominal_CPUE = sum(daily_CPUE_kg, na.rm = TRUE) / 1000,       # Convert to metric tons
Monthly_Standardized_CPUE = sum(Standardized_CPUE, na.rm = TRUE) / 1000  # Convert to metric tons
) %>%
gather(key = "CPUE_Type", value = "CPUE_Value", Monthly_Nominal_CPUE, Monthly_Standardized_CPUE)
# Create multi-faceted graph
ggplot(complex_gam_ia_catch_summary, aes(x = factor(Month), y = CPUE_Value, color = CPUE_Type, group = CPUE_Type)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
facet_wrap(~ Year, scales = "free_y", ncol = 3) +
scale_color_manual(values = c("Monthly_Nominal_CPUE" = "blue", "Monthly_Standardized_CPUE" = "red"),
labels = c("Nominal CPUE", "Standardized CPUE")) +
theme_minimal() +
labs(
title = "Monthly Comparison of Summed CPUE Types by Year (2000-2020)",
x = "Month",
y = "CPUE (metric tons)"
) +
scale_y_continuous(labels = scales::comma) +
theme(
legend.title = element_blank(),
strip.text = element_text(size = 8),
legend.position = "bottom"
)
# Summarize the data by Year
annual_summary <- complex_gam_ia_catch %>%
group_by(Year) %>%
summarise(
Total_Nominal_CPUE = sum(daily_CPUE_kg, na.rm = TRUE) / 1000,         # Convert to metric tons
Total_Standardized_CPUE = sum(Standardized_CPUE, na.rm = TRUE) / 1000  # Convert to metric tons
) %>%
gather(key = "CPUE_Type", value = "CPUE_Value", Total_Nominal_CPUE, Total_Standardized_CPUE)
# Create the single graph
# Replace 0 with NA in a specific column (e.g., Column1)
annual_summary$CPUE_Value[annual_summary$CPUE_Value == 0] <- NA
ggplot(annual_summary, aes(x = Year, y = CPUE_Value, color = CPUE_Type, group = CPUE_Type)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
scale_color_manual(values = c("Total_Nominal_CPUE" = "blue", "Total_Standardized_CPUE" = "red"),
labels = c("Nominal CPUE", "Standardized CPUE")) +
theme_minimal() +
labs(
title = "Annual Comparison of Total CPUE Types (2000-2020) for General Additive Model",
x = "Year",
y = "Total CPUE (metric tons)"
) +
scale_y_continuous(labels = scales::comma) +
theme(
legend.title = element_blank(),
legend.position = "bottom"
)
# Save results to an Excel file
wb <- createWorkbook()
# Add the full dataset with predictions for the last 3 months
addWorksheet(wb, "Last_Five_Years")
writeData(wb, "Last_Five_Years", annual_summary[38:42,])
# Add regression results for each year
addWorksheet(wb, "Regression_Results")
writeData(wb, "Regression_Results", regression_results_df)
# Add regression results for each year
addWorksheet(wb, "full_Results")
writeData(wb, "full_Results", annual_summary)
# Save the Excel workbook
saveWorkbook(wb, "Regression_and_Standardized_CPUE_GAM_complex_model.xlsx", overwrite = TRUE)
# Print a success message
cat("Results saved to 'Regression_and_Standardized_CPUE_GAM_complex_model.xlsx'")
27370-27208
162*5
8300*810
8300+810
30/38*100
37/38
160000+40000
file.exists("Documents/GitHub/Squid-Fest/0-Certified_Reference_Materials(CRMs)/ICP_MS_Data.csv")  # Returns TRUE if the file exists
getwd()
setwd("/Users/mrnobody/Documents")
setwd("/Users/mrnobody/Documents/GitHub/Squid-Fest")
file.info("0-Certified_Reference_Materials(CRMs)/ICP_MS_Data.csv")
read.csv("0-Certified_Reference_Materials(CRMs)/ICP_MS_Data.csv")
readLines("0-Certified_Reference_Materials(CRMs)/ICP_MS_Data.csv", n = 10)
setwd("/Users/mrnobody/Documents/GitHub/Squid-Fest")
certified_values <- data.frame(
Element = c("Fe", "Co", "Ni", "Cu", "Zn", "Ag", "Cd", "Hg", "Pb"),
Certified_Value_mg/kg = c(205.8, 0.371, 1.04, 71.6, 1424, 0.666, 2.48, 0.0317, 0.308),
cert_vs_meas <- data.frame(
Element = c("Fe", "Co", "Ni", "Cu", "Zn", "Ag", "Cd", "Hg", "Pb"),
Certified = c(205.8, 0.371, 1.04, 71.6, 1424, 0.666, 2.48, 0.0317, 0.308),
Measured = c(mean(c(124.76, 122.09, 165.52, 131.88, 137.74)),
mean(c(0.34, 0.56, 0.33, 0.41, 0.44)),
mean(c(1.20, 2.23, 1.33, 1.28, 1.45)),
mean(c(62.57, 48.50, 64.81, 59.38, 61.09)),
mean(c(1059.78, 930.30, 1187.62, 1094.63, 1138.52)),
mean(c(0.48, 0.47, 0.62, 0.55, 0.58)),
mean(c(1.97, 1.64, 2.14, 1.96, 2.08)),
mean(c(0.096, 0.047, 0.095, 0.046, 0.048)),
mean(c(1.54, 0.52, 0.57, 0.50, 0.53)))
)
View(cert_vs_meas)
install.packages("kableExtra")
yes
install.packages("kableExtra")
install.packages("kableExtra")
install.packages("svglite", type = "source")
Sys.setenv(PKG_CONFIG_PATH = "/opt/homebrew/lib/pkgconfig")
install.packages("svglite", type = "source")
install.packages(
"svglite",
type = "source",
configure.vars = "CPPFLAGS='-I/opt/homebrew/include' LDFLAGS='-L/opt/homebrew/lib'"
)
install.packages("svglite", type = "source")
install.packages("kableExtra")
setwd("/Users/mrnobody/Documents/GitHub/Squid-Fest/0-Certified_Reference_Materials_CRMs")
![ICP-MS screenshot](Data/ICP_MS_screenshot.png)
